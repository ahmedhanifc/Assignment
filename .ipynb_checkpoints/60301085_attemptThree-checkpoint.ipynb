{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601ef4c3-50f3-47de-9102-7f8552a263e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'Ahmed Hanif - 60301085'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6609a24c-cecc-4a8b-9830-3e32d3180a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from quantile_forest import RandomForestQuantileRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report,  precision_score, recall_score, f1_score, auc, roc_curve\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, PoissonRegressor\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0453c72-c326-478c-b689-36e4125ced14",
   "metadata": {},
   "source": [
    "<b> Functions Utilized</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28522fd7-a694-473b-94d9-161c90658865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bin_edges(column, bin_boundary):\n",
    "    return np.arange(0,column.max() + bin_boundary, bin_boundary)\n",
    "\n",
    "def normalize(x, condition = False):\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "def denormalize(original, normalized):\n",
    "    return normalized * (original.max() - original.min()) + original.min() # (TracyRenee, n.d.)\n",
    "def logtrans(x, inverse= False):\n",
    "    if inverse == False:\n",
    "        return np.log(x)\n",
    "    elif inverse == True:\n",
    "        return np.power(2,x)\n",
    "\n",
    "def remove_outliers(df, columns):\n",
    "    for column in columns:\n",
    "        Q1 = df['column'].quantile(0.25)\n",
    "        Q3 = df['column'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06644161-5361-4c2b-b0a6-0b6a9eebc79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verOne = pd.read_csv('Breast_Cancer-Winter2024.csv')\n",
    "df_verOne.columns = df_verOne.columns.str.replace(' ','_').str.lower()\n",
    "df_verOne.rename(columns = {'t_stage_' : 't_stage', 'reginol_node_positive': 'regional_node_positive', '6th_stage': 'sixth_stage'}, inplace = True)\n",
    "print('Number Of Rows:',df_verOne.shape[0])\n",
    "print('Duplicated Rows:', df_verOne.duplicated().sum())\n",
    "df_verOne.drop_duplicates(inplace=True)\n",
    "df_verOne.sample(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0416f1-7d35-47c5-88b3-a9dcaaad3393",
   "metadata": {},
   "source": [
    "<b>Q1 - a - Distribution of Death Event cases among patients and race</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf79d72e-24f7-4933-a0c8-0d5c09be63f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count_of_each_race = df_verOne['race'].value_counts()\n",
    "print(total_count_of_each_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813b3b28-36f7-4f5a-8552-7057f6681302",
   "metadata": {},
   "outputs": [],
   "source": [
    "death_count_of_each_race = df_verOne['race'][df_verOne['status'] == 'Dead'].value_counts()\n",
    "print(death_count_of_each_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd579a8-7147-4164-940e-881dd33ef405",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_death_cases = (df_verOne['status'] == 'Dead').sum()\n",
    "print(total_death_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea3eb1-1334-4110-98c4-201509a1b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "death_percentage_of_each_race = round((death_count_of_each_race / total_death_cases) * 100,2)\n",
    "print(death_percentage_of_each_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7715bfa-d51d-4ae4-bb92-34fae0163446",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8));\n",
    "plt.subplot(1,2,1)\n",
    "plt.pie(total_count_of_each_race, labels = df_verOne['race'].value_counts().index, autopct='%.0f%%' );\n",
    "plt.title(\"Percentage of Race Distribution\");\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.pie(death_count_of_each_race, labels = df_verOne['race'].value_counts().index, autopct='%.0f%%', );\n",
    "plt.title(\"Death Percentage of each Race\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe0a54f-bd71-4133-afb1-f119ba33d35c",
   "metadata": {},
   "source": [
    "<h3> Interpretation</h3>\n",
    "<p>Amongst all those who died, 83% Of were white, 5% were black, and 12% were of other ethnicity</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56594c2c-c1e6-4e9b-b678-cd1e59824929",
   "metadata": {},
   "source": [
    "<b> Q1 - b - Descripting Statistics of Data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ef6a7d-b02d-4bc8-8fdc-86c31d13a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptive_stats_of_data = round(df_verOne.describe().T,2)\n",
    "descriptive_stats_of_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab9a74e-5808-41d1-81b6-a830c5eac982",
   "metadata": {},
   "source": [
    "<p><b>Age:</b></p>\n",
    "<p>    The average age of the patients is almost 54 years old. 25% of the patients are below 47 years of age, whereas 75% of the patients are above 61. The Maximum age of the patient is 69....</p>\n",
    "<p><b>tumor_size:</b></p>\n",
    "<p>    The average tumour size among the patients was found to be 30.42. The minimum size of the tumour is 0mm and the maximum size is 140mm.25% of the patients had a tumor size of less that 16mm while 25% of the patients had tumor size of greater than 38mm.</p>\n",
    "<p><b>regional_node_examined and regional_node_positive:</b></p>\n",
    "<p>    The average of 14.36 patients had their regional node examined, out of which it returned positive for 4.16 of the patients. The maximum of the regional nodes that were examined are 75. And the maximum that came back positive are 46</p>\n",
    "<p><b>survival_months: </b></p>\n",
    "<p>    The average number of months that patients survived after being diagnosed is 71. 25% of the patients survived for less than 56 months whereas 90% of the patients survived for 90 months. The maximum time that any patient survived is 107 months, which are approximately 9 years</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c398f02-63c0-4743-b30a-0b5d91a0974d",
   "metadata": {},
   "source": [
    "<b>Q1 - c - Skew and Kurtosis</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cda50e-c45e-4a60-9dad-514a1f0a444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = df_verOne.select_dtypes(include = [np.number])\n",
    "skew_and_kurtosis = round(numerical_columns.agg(['skew','kurtosis']).T,2)\n",
    "skew_and_kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b154cab8-dd4b-486f-bb3d-8cb495e97e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,10))\n",
    "plt.subplot(2,2,1)\n",
    "sb.histplot(numerical_columns.tumor_size, kde= True, bins = calculate_bin_edges(numerical_columns.tumor_size,8));\n",
    "plt.title('Hist Plot of Tumor Size');\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "sb.histplot(numerical_columns.regional_node_examined, kde = True,bins = calculate_bin_edges(numerical_columns.regional_node_examined,4))\n",
    "plt.title('Hist Plot of Examination of Regional Node')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "sb.histplot(numerical_columns.survival_months, kde = True, bins = calculate_bin_edges(numerical_columns.survival_months,8))\n",
    "plt.title('Hist Plot of Examination of Survival Months')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "sb.histplot(numerical_columns.regional_node_positive, kde = True, bins = calculate_bin_edges(numerical_columns.regional_node_positive,3))\n",
    "plt.title('Hist Plot of Positive Regional Node Results')\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9ea893-9459-4285-acbe-f7e41957b65f",
   "metadata": {},
   "source": [
    "<h3>Interpretation</h3>\n",
    "<p>\n",
    "    <ul>\n",
    "        <li>The <i>tumor size</i>,<i> Examination of regional node</i>, and <i>Regional Node coming back positive</i> is skewed to the right, so mean is greater than the median. This means that outliers are present to the right side of their respective distributions</li>\n",
    "        <li>The <i>Survival Months</i> distribution of patients is skewed to the left. The mean is less than median. The outliers are present on left side of the distribution.</li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3838fb-9399-481b-8710-b9f644f7a0a1",
   "metadata": {},
   "source": [
    "<b> Q2 - Univariate Plots</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7432911b-851d-494f-8c90-bb9a6df0ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dead_patients = df_verOne[df_verOne['status'] == 'Dead']\n",
    "\n",
    "fig, ax = plt.subplots(4,2, figsize = (16,12))\n",
    "fig.suptitle(\"Figure 1. Analysis of Medical Variables with respect to Death Status\", fontsize = 32)\n",
    "\n",
    "color = sb.color_palette()[3]\n",
    "order = dead_patients['race'].value_counts().index\n",
    "sb.countplot(data = dead_patients, x = 'race', ax = ax[0,0], color = color, order= order)\n",
    "ax[0,0].set_title(\"Death Distribution with regards to Race\")\n",
    "ax[0,0].set_ylabel(\"Death Count\")\n",
    "ax[0,0].set_xlabel(\"Race Count\")\n",
    "\n",
    "color = sb.color_palette()[4]\n",
    "order = dead_patients['marital_status'].value_counts().index\n",
    "sb.countplot(dead_patients,x = 'marital_status', order = order, color = color, ax = ax[0,1])\n",
    "ax[0,1].set_title('Death Distribution with regards to Marital Status')\n",
    "ax[0,1].set_ylabel(\"Death Count\")\n",
    "ax[0,1].set_xlabel(\"Marital Status of Patients\")\n",
    "\n",
    "color = sb.color_palette()[2]\n",
    "# order = dead_patients['t_stage'].value_counts().index\n",
    "sb.countplot(x = dead_patients['t_stage'], color = color, ax = ax[1,0], order = ['T1','T2','T3','T4']) #Ordinal Data -- Order Matters. Higher Numbers indicate greater extent of the disease\n",
    "ax[1,0].set_title('Death Distribution with regards to Tumor Stage of Patients')\n",
    "ax[1,0].set_ylabel(\"Death Count\")\n",
    "ax[1,0].set_xlabel(\"Tumor Stage of Patients\")\n",
    "\n",
    "color = sb.color_palette()[1]\n",
    "order = dead_patients['n_stage'].value_counts().index\n",
    "sb.countplot(x = dead_patients['n_stage'], order = ['N1','N2','N3'], color = color, ax = ax[1,1])\n",
    "ax[1,1].set_title('Death Distribution with regards Spread of Cancer to Nearby nodes')\n",
    "ax[1,1].set_ylabel(\"Death Count\")\n",
    "ax[1,1].set_xlabel(\"Node Stage of Patients\")\n",
    "\n",
    "color = sb.color_palette()[0]\n",
    "order = dead_patients['sixth_stage'].value_counts().index\n",
    "sb.countplot(x = dead_patients['sixth_stage'], color = color, ax = ax[2,0], order = ['IIA','IIB','IIIA','IIIB','IIIC'])\n",
    "ax[2,0].set_title('TNM Classification of Patients and its relation to Death')\n",
    "ax[2,0].set_ylabel(\"Death Count\")\n",
    "ax[2,0].set_xlabel(\"Sixth Stage of Patients\")\n",
    "\n",
    "color = sb.color_palette()[5]\n",
    "order = dead_patients['differentiate'].value_counts().index\n",
    "sb.countplot(x = dead_patients['differentiate'], color = color, ax = ax[2,1], order = ['Undifferentiated', 'Poorly differentiated','Moderately differentiated','Well differentiated'])\n",
    "ax[2,1].set_title('TNM Classification of Patients and its relation to Death')\n",
    "ax[2,1].set_ylabel(\"Death Count\")\n",
    "ax[2,1].set_xlabel(\"Sixth Stage of Patients\")\n",
    "for tick in ax[2,1].get_xticklabels():\n",
    "    tick.set_rotation(10) # (GfG, 2022)\n",
    "\n",
    "color = sb.color_palette()[6]\n",
    "sb.countplot(x = dead_patients['grade'], color = color, ax = ax[3,0], order = ['1','2','3',' anaplastic; Grade IV'])\n",
    "ax[3,0].set_title('Grade of the Tumor and its relation to Death')\n",
    "ax[3,0].set_ylabel(\"Death Count\")\n",
    "ax[3,0].set_xlabel(\"Grade of the Tumor Of Patients\")\n",
    "\n",
    "color = sb.color_palette()[7]\n",
    "sb.countplot(x = dead_patients['a_stage'], color = color, ax = ax[3,1])\n",
    "ax[3,1].set_title('Anatomical Stage and its relation to Death')\n",
    "ax[3,1].set_ylabel(\"Death Count\")\n",
    "ax[3,1].set_xlabel(\"Anatomical Stage Of Patients\")\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f1ec6-d5c9-4f6d-b47e-f5f6b2339531",
   "metadata": {},
   "source": [
    "<h3> Interpretation</h3>\n",
    "<p>\n",
    "    <ul>\n",
    "        <li><b>Classes of People Who are more Likely to die from cancer are:</b>\n",
    "            <ul>\n",
    "                <li>White</li>\n",
    "                <li>Married</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>People who have Tumor Stage of T2 died more frequently than all other stages, with higher stage implying greater extent of the disease. The same is true for peeple who have N1 stage lymph involvement. The above results are combined in one criterion called sixth stage, in which patients who were diagnosed with IIIA disease died more frequently</li>\n",
    "        <li>Surprisingly, people who's cancer was moderately differentiated, suggesting that it was a slow growing and less aggressive cancer, died more frequently than other types.</li>\n",
    "        <li>\n",
    "            Finally, patients with grade 2 and 3 cancer suffered the most deaths, as well as those patients who cancer had spread beyond the original site \n",
    "        </li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c9279-7bb4-48b3-8a85-ed4d9c1d249b",
   "metadata": {},
   "source": [
    "<b>Q3 - Multivariate Plots</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3552a8-dc09-44d1-8559-eccc7dfc6131",
   "metadata": {},
   "source": [
    "<b> a </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588d807c-e2ed-4819-b732-65c5e290a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b3b718-81d6-472c-89d5-9d1821c2ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Analyzing Correlation amongst Numerical Columns');\n",
    "sb.heatmap(data = numerical_columns.corr(), cmap = 'Blues_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bafefc-34f4-4384-827b-c860839e6646",
   "metadata": {},
   "source": [
    "<b> Important Findings </b>\n",
    "<ul>\n",
    "    <li>There is a negative correlation between Survival Month and Tumor Size. This means that the greater tumour size you have, the less number of months you will survive</li>\n",
    "    <li>\n",
    "        There is a slight negative correlation between survival months and your regional node test coming back positive\n",
    "    </li>\n",
    "    <li>\n",
    "        There is a slight positive link b/w you examining your regional node and it coming back positive. Likewise with your regional node coming back positive and tumor size.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e177e7-ec30-45fa-aa41-d140b24fb728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4d12c9-2e3b-4c46-9556-ac0df5f77ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_tumour_size = normalize(numerical_columns['tumor_size'])\n",
    "norm_survival_months = normalize(numerical_columns['survival_months'])\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (12,6))\n",
    "fig.suptitle('Figure 3. Analysis of Relationship between tumor size and survival months', fontsize = 16)\n",
    "\n",
    "sb.regplot(data = numerical_columns,x = norm_tumour_size, y = norm_survival_months, x_jitter= 0.1, y_jitter=0.1, scatter_kws= {'alpha': 1/4}, ax=ax[0])\n",
    "ax[0].set_title('Normalized relationship between tumor size and survival months')\n",
    "ax[0].set_ylabel('Survival Months')\n",
    "ax[0].set_xlabel('Tumor Size')\n",
    "\n",
    "sb.regplot(x = numerical_columns['tumor_size'], y = numerical_columns['survival_months'], x_jitter= 1, y_jitter=1, scatter_kws= {'alpha': 1/4}, ax = ax[1])\n",
    "ax[1].set_title('Relationship between tumor size and survival months')\n",
    "ax[1].set_ylabel('Survival Months')\n",
    "ax[1].set_xlabel('Tumor Size')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ae05db-1d4d-41e8-b274-52106308f793",
   "metadata": {},
   "source": [
    "<b>b</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb2df15-3427-4a99-9db0-471f0130124a",
   "metadata": {},
   "source": [
    "<b> Analyzing distributions with respect to marital status </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8da61c-6776-4df4-8fc2-3fa4d20bcd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (12,8))\n",
    "\n",
    "sb.violinplot(y = dead_patients['marital_status'], x = dead_patients['age'], ax = ax[0])\n",
    "ax[0].set_title('Age of Patients with regards to marital status')\n",
    "sb.violinplot(y = dead_patients['marital_status'], x = dead_patients['survival_months'], ax = ax[1])\n",
    "ax[1].set_title('Survival Months of Patients with regards to marital status')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c901117-6d59-472e-a183-ad97d140d547",
   "metadata": {},
   "source": [
    "There seems to be no apparent link amongst how medical variable would cause more death amongst married people than non-married people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ee3365-a1cf-4898-966e-b35ad8254685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verOne.groupby('marital_status')['status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d618d53-a4a5-4482-88e6-b5a2ff1fc7d8",
   "metadata": {},
   "source": [
    "<b> Q4 - Identifying and Removing Outliers </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3310a5c-419d-49c5-be7e-85cb8fc39961",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verTwo = df_verOne.copy()\n",
    "\n",
    "fig, ax = plt.subplots(3,2, figsize = (12,12))\n",
    "fig.suptitle('Figure 4. Before Removing Outliers', fontsize=16)\n",
    "\n",
    "sb.boxplot(data = df_verTwo, x = df_verTwo['tumor_size'], ax=ax[0, 0])\n",
    "ax[0,0].set_xlabel('Tumor Size of Patients')\n",
    "\n",
    "sb.boxplot(data = df_verTwo, x = df_verTwo['age'], ax = ax[0,1])\n",
    "sb.boxplot(data = df_verTwo, x = df_verTwo['regional_node_examined'], ax = ax[1,0])\n",
    "ax[1,0].set_xlabel('Number of Patients whose regional node was examined')\n",
    "sb.boxplot(data = df_verTwo, x = df_verTwo['regional_node_positive'], ax = ax[1,1])\n",
    "ax[1,1].set_xlabel('Number of Patients whose regional node was positive')\n",
    "sb.boxplot(data = df_verTwo, x = df_verTwo['survival_months'], ax = ax[2,0])\n",
    "ax[2,0].set_xlabel('Survival Months')\n",
    "\n",
    "ax[2,1].axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2133a65f-49c5-40dd-b694-15ab0e800dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "# df_verTwo['tumor_size'] = winsorize(df_verTwo['tumor_size'], limits=[0.08,0.08]) #8% top and 8% bottom replaced by 92th and 8th percentile respectively\n",
    "df_verTwo['regional_node_examined'] = winsorize(df_verTwo['regional_node_examined'], limits = [0,0.1])\n",
    "df_verTwo['regional_node_positive'] = winsorize(df_verTwo['regional_node_positive'], limits = [0,0.1])\n",
    "df_verTwo['survival_months'] = winsorize(df_verTwo['survival_months'], limits = [0.05,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00a6541-5879-45e5-a37b-2edc0781f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,2, figsize = (12,12))\n",
    "fig.suptitle('Figure 5. After Removing Outliers', fontsize=16)\n",
    "\n",
    "sb.boxplot(data = df_verTwo, x = df_verTwo['tumor_size'], ax=ax[0, 0])\n",
    "ax[0,0].set_xlabel('Tumor Size of Patients')\n",
    "\n",
    "sb.boxplot(data = df_verTwo, x = df_verTwo['age'], ax = ax[0,1])\n",
    "sb.boxplot(data = df_verTwo, x = df_verTwo['regional_node_examined'], ax = ax[1,0])\n",
    "ax[1,0].set_xlabel('Number of Patients whose regional node was examined')\n",
    "sb.boxplot(data = df_verTwo, x = df_verTwo['regional_node_positive'], ax = ax[1,1])\n",
    "ax[1,1].set_xlabel('Number of Patients whose regional node was positive')\n",
    "sb.boxplot(data = df_verTwo, x = df_verTwo['survival_months'], ax = ax[2,0])\n",
    "ax[2,0].set_xlabel('Survival Months')\n",
    "\n",
    "ax[2,1].axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7721d542-9836-4fbe-bf22-b2b5dfffdf50",
   "metadata": {},
   "source": [
    "<h3>Explanation</h3>\n",
    "<p>\n",
    "    <ul>\n",
    "        <li>\n",
    "            For Examining Outliers, we used the boxplots. The shape of the boxplot shows how the data is distributed and it also shows any outliers. (Numeracy, Maths and Statistics - Academic Skills Kit, n.d.)\n",
    "        </li>\n",
    "        <li>\n",
    "            <b>Rationale for not Winsorizing Tumor Size: </b>\n",
    "            Tumor Size contains lots of zero values. We will be examining that further down the road\n",
    "        </li>\n",
    "        <li>\n",
    "            With Regards to others:\n",
    "            <ul>\n",
    "                <li><b>Regional Node Examination and Regional node Positive: </b>According to Figure 4, These distribution contained alot of outliers on the right side, hence we replaced 10% of all the outliers on the right side with the 90th Percentile Value</li>\n",
    "                <li><b>Survival Months: </b>According to Figure 4, This distribution contained alot of outliers on the left side, hence we replaced 5% of all the outliers on the right side with the 95th Percentile Value</li>\n",
    "                <!-- <li><b></b></li> -->\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd333e9-2c93-4124-9f7f-880fa7becb73",
   "metadata": {},
   "source": [
    "<b>Q5 - Treating Missing Values</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e8493-2280-4025-bdcf-27b3163ee5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_verTwo.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d76c46-b2e3-4f9c-84d9-40f63a9d94c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verTwo['t_stage'] = df_verTwo['t_stage'].fillna(df_verTwo['t_stage'].mode().iat[0])\n",
    "df_verTwo['differentiate'] = df_verTwo['differentiate'].fillna(df_verTwo['differentiate'].mode().iat[0])\n",
    "df_verTwo['survival_months'] = df_verTwo['survival_months'].fillna(df_verTwo['survival_months'].mean())\n",
    "df_verTwo.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91206f79-4f89-4c53-b467-fdb4d614fd2e",
   "metadata": {},
   "source": [
    "<h3>Explanation</h3>\n",
    "<p>\n",
    "    <ul>\n",
    "        <li>Categorial Variables t_stage was replaced with the mode</li>\n",
    "        <li>Numerical Variable such as tumor_size and survival_months was replaced with the mean. The reason for choosing mean was because we had removed outliers in the previous step.</li>\n",
    "        <!-- <li></li> -->\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92783870-e50e-4973-a5c4-39bb6b93bdf4",
   "metadata": {},
   "source": [
    "<b>Q6 - Impute Zeroes</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a9bc65-d1be-4857-9f2f-8a0a2004f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '0' in df_verTwo['progesterone_status'][df_verTwo['progesterone_status'] == '0'].values.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0bc331-42ba-4421-b4d2-c16ccc680561",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_verTwo.columns.tolist()\n",
    "toImpute = []\n",
    "for column in columns:\n",
    "    if '0' in (df_verTwo[column][(df_verTwo[column] == '0') | (df_verTwo[column] == 0)].values).astype('str'):\n",
    "        toImpute.append(column)\n",
    "print(df_verTwo[toImpute].value_counts())\n",
    "df_verTwo[toImpute] = df_verTwo[toImpute].replace('0','Negative')\n",
    "print('After Imputing:','0' in df_verTwo[toImpute][df_verTwo[toImpute] == '0'].values.astype('str'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b9275f-4d46-405b-9023-0c3151e33c5f",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <b> Explanation </b>\n",
    "    <ul>\n",
    "        <li>\n",
    "                <p> progesterone_status column has three types of values. Since the negative value already exists, we don't have a need for the '0' value as they both represent the same thing. Hence, we will be imputing that with negative </p>\n",
    "        </li>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f839f6a7-1672-4f36-b0de-c13e8aa320a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verOne[['t_stage', 'tumor_size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa5af68-b060-44e0-b09c-1750514903c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verTwo[['t_stage', 'tumor_size']][df_verTwo['tumor_size'] == 0].size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b528ac64-ee64-4388-b422-b82defc1749b",
   "metadata": {},
   "source": [
    "<p>Tumor from stage 1 onwards don't have a tumor size of zero. Hence we will be imputing these values</p>(Breast Cancer Tumor Size Chart & Measurement Explained, n.d.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe119f34-a1dd-4e05-861f-31e43a87614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verTwo['tumor_size'] = winsorize(df_verTwo['tumor_size'], limits = [0.08,0.08])\n",
    "df_verTwo[['t_stage', 'tumor_size']][df_verTwo['tumor_size'] == 0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2988f09-6bdf-439c-a3ac-ce651e24a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verTwo['progesterone_status'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536d6fb2-761d-4e51-adfa-511c5c468d3f",
   "metadata": {},
   "source": [
    "<b> Q7 - Rescale </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea1fa7-4681-4e9d-a1c2-a5ead30eb4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verThree = df_verTwo.copy()\n",
    "\n",
    "print(df_verThree['grade'].unique())\n",
    "df_verThree['grade'] = df_verThree['grade'].replace(' anaplastic; Grade IV', '4')\n",
    "print('After Replacing:',df_verThree['grade'].unique())\n",
    "\n",
    "\n",
    "type_of_object_columns = df_verThree.select_dtypes(include = ['object'])\n",
    "df_verThree[type_of_object_columns.columns.tolist()]=df_verThree[type_of_object_columns.columns.tolist()].astype('category')\n",
    "# df_verThree['status'] = df_verThree['status'].str.replace('Alive', '1').str.replace('Dead', '0')\n",
    "# df_verThree['status'] = df_verThree['status'].astype('int')\n",
    "df_verThree['status'] = df_verThree['status'].cat.codes\n",
    "\n",
    "\n",
    "df_verThree['estrogen_status'] = df_verThree['estrogen_status'].cat.codes\n",
    "df_verThree['progesterone_status'] = df_verThree['progesterone_status'].cat.codes\n",
    "\n",
    "df_verThree['a_stage'] = df_verThree['a_stage'].cat.codes\n",
    "\n",
    "df_verThree['tumor_size'] = round(normalize(df_verThree['tumor_size']),2)\n",
    "df_verThree['survival_months'] = round(normalize(df_verThree['survival_months']),2)\n",
    "\n",
    "df_verFour = df_verThree.copy()\n",
    "df_verFour = pd.get_dummies(df_verThree, prefix = ['differentiate', 'marital_status', 't_stage','sixth_stage'], columns = ['differentiate', 'marital_status', 't_stage','sixth_stage'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d05789b-bab4-46a8-bb91-17537f20e5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verFour.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeb7261-4b3c-4941-933e-399837d1f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verFour.columns = df_verFour.columns.str.replace(' ','_').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0690c8-125a-482b-a2e9-fc06c50b4ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe3d1b-89f2-4a26-ab81-5fa47a2532c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_verFour.columns.tolist()\n",
    "r_one = re.compile('differentiate*')\n",
    "differentiate_columns = list(filter(r_one.match, columns)) #(Regular Expressions: Search in List, n.d.)\n",
    "print(differentiate_columns)\n",
    "\n",
    "r_two = re.compile('marital_status*')\n",
    "relationship_status_columns = list(filter(r_two.match, columns))\n",
    "print(relationship_status_columns)\n",
    "\n",
    "r_three = re.compile('t_stage*')\n",
    "t_stage_columns = list(filter(r_three.match,columns))\n",
    "print(t_stage_columns)\n",
    "\n",
    "# r_four = re.compile('n_stage*')\n",
    "# n_stage_columns = list(filter(r_four.match, columns))\n",
    "# print(n_stage_columns)\n",
    "\n",
    "r_five = re.compile('sixth_stage*')\n",
    "sixth_stage_columns = list(filter(r_five.match, columns))\n",
    "print(sixth_stage_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a2636-0fd4-45ac-9905-489324d7195c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verThree['a_stage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b94a62-e848-4857-a44d-d02d38dd8488",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_columns = differentiate_columns + ['grade', 'tumor_size', 'survival_months','status']\n",
    "df_verFour.groupby('status')[['tumor_size','survival_months']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf16ca18-75c1-4016-be97-1acfe5b95bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.regplot(x = df_verFour['tumor_size'], y = df_verFour['survival_months'], x_jitter=0.05, y_jitter=0.05, scatter_kws={'alpha': 0.3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d698b5f-a61c-446f-b08a-52f942f5708e",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>Label Encoding:</b> Changing Categorical Type into Numerical in order to feed to the model later down the road. In label encoding, we assign 0 and 1 without creating a new column. This works best when we have few categorical values...</li>\n",
    "    <ul>\n",
    "        <li>\n",
    "            <b>Status:</b> Alive = 1, Dead = 0\n",
    "        </li>\n",
    "        <li>\n",
    "            <b>Progesterone Status:</b> Positive = 1, Negative = 0\n",
    "        </li>\n",
    "        <li>\n",
    "            <b>Estrogen Status:</b> Positive = 1, Negative = 0\n",
    "        </li>\n",
    "        <li>\n",
    "            <b>a_stage:</b> Regional = 1, Distant = 0\n",
    "        </li>\n",
    "    </ul>\n",
    "<li>\n",
    "    <b>Normalizing:</b> Converting Values to a similar scale in order to improve the efficiency of the model\n",
    "    <ul>\n",
    "        <li>\n",
    "            <b>Tumor Size</b>\n",
    "        </li>\n",
    "        <li>\n",
    "            <b>Survival Months</b     \n",
    "        </li>\n",
    "    </ul>\n",
    "</li>\n",
    "    <li>\n",
    "        <b>One Hot Encoding: </b> Changing Categorical type to numerical in order to feed to the model further down the road. One hot encoding works best when we have categorical data with many distinct categorical values. In this scenario, label encoding is not the best option as it may cause bias within the model\n",
    "    </li>\n",
    "    <ul>\n",
    "    <li><b>differentiate</b></li>\n",
    "    <li><b>marital_status</b></li>\n",
    "    <li><b>t_stage</b></li>\n",
    "    <li><b>sixth_stage</b></li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d0d738-4867-4b23-8a2d-2f6b28427140",
   "metadata": {},
   "source": [
    "<b>Q8 - Feature Engineering and Feature Removal</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfba517c-f4ee-4205-a721-97af70ec1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verFive = df_verFour.copy()\n",
    "df_verFive['survival_chance'] = (df_verFive['tumor_size'] * df_verFive['survival_months']) * 100\n",
    "\n",
    "feature_removal = ['estrogen_status', 'progesterone_status', 'race']\n",
    "df_verFive.drop(columns = feature_removal, inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9436a700-3cd1-495b-9b02-c2ad4d3f71a3",
   "metadata": {},
   "source": [
    "<h3>Comments</h3>\n",
    "<ul>\n",
    "    <li>\n",
    "        Feature Engineering: I added a survival chance column based on the current number of months the patient had survived (normalized) and their tumor size\n",
    "    </li>\n",
    "    <li>\n",
    "        I removed the columns show in feature_removal variable as those columns are useful when determining whether a patient will respond to a specific therapy or not, which in our case is not very useful as we are trying to predict death status and/or survival months. Same reasong with race.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7090c7-278c-4554-8917-c5711d76b97b",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be244b4-dea4-4b7d-81d5-a7f2ed4fd858",
   "metadata": {},
   "source": [
    "<h1>Machine Learning</h1>\n",
    "<p><b> Classification Problem:</b> Determine if the patient Survived or Not</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d2df3f-75a4-459e-9f22-797af46f98e1",
   "metadata": {},
   "source": [
    "Splitting Calling Fitting Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faa94d6-bafc-4f01-a7da-3f814b74c2c5",
   "metadata": {},
   "source": [
    "<b>Q1 </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab87d5c3-6d78-491c-953e-d9a009456d30",
   "metadata": {},
   "source": [
    "<b> Test One </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2274f3b-5f64-46c4-bac3-5e74b94cd03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_number_one = differentiate_columns + relationship_status_columns + ['age']\n",
    "\n",
    "feature_set_one = test_number_one\n",
    "target_set_one = ['status']\n",
    "feature_one = df_verFive.loc[:,feature_set_one]\n",
    "target_one = df_verFive.loc[:,target_set_one]\n",
    "\n",
    "Xtrain_one, Xtest_one, ytrain_one, ytest_one = train_test_split(\n",
    "    feature_one,\n",
    "    target_one,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_one = RandomForestClassifier()\n",
    "model_one.fit(Xtrain_one, ytrain_one)\n",
    "ypredict_one = model_one.predict(Xtest_one)\n",
    "\n",
    "accuracy_one = accuracy_score(ytest_one, ypredict_one)\n",
    "matrix_one = confusion_matrix(ytest_one, ypredict_one)\n",
    "precision_one = precision_score(ytest_one, ypredict_one, average='weighted', labels = np.unique(ypredict_one))\n",
    "recall_one = recall_score(ytest_one, ypredict_one, average='weighted', labels = np.unique(ypredict_one))\n",
    "f1_one = f1_score(ytest_one, ypredict_one, average='weighted', labels = np.unique(ypredict_one))\n",
    "\n",
    "score_summary = {'Accuracy':round(accuracy_one,2), 'Precision':round(precision_one,2), 'Recall': round(recall_one,2), 'F1': round(f1_one,2)}\n",
    "\n",
    "fpr_one, tpr_one, threshold_one = roc_curve(ytest_one, ypredict_one)\n",
    "roc_auc_one = auc(fpr_one, tpr_one)\n",
    "\n",
    "\n",
    "for key, value in score_summary.items():\n",
    "    print(f'{key} Score is: {value}')\n",
    "print(matrix_one)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648e8b76-5449-4aba-921c-4ff3c9304ca0",
   "metadata": {},
   "source": [
    "<b> Test Two </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da86145c-ef2a-4915-b64c-ee849dceec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_number_two = relationship_status_columns \n",
    "\n",
    "feature_set_two = test_number_two\n",
    "target_set_two = ['status']\n",
    "feature_two = df_verFive.loc[:,feature_set_two]\n",
    "target_two = df_verFive.loc[:,target_set_two]\n",
    "\n",
    "Xtrain_two, Xtest_two, ytrain_two, ytest_two = train_test_split(\n",
    "    feature_two,\n",
    "    target_two,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_two = LogisticRegression()\n",
    "model_two.fit(Xtrain_two, ytrain_two)\n",
    "ypredict_two = model_two.predict(Xtest_two)\n",
    "\n",
    "accuracy_two = accuracy_score(ytest_two, ypredict_two)\n",
    "matrix_two = confusion_matrix(ytest_two, ypredict_two)\n",
    "precision_two = precision_score(ytest_two, ypredict_two, average='weighted', labels = np.unique(ypredict_two))\n",
    "recall_two = recall_score(ytest_two, ypredict_two, average='weighted', labels = np.unique(ypredict_two))\n",
    "f1_two = f1_score(ytest_two, ypredict_two, average='weighted', labels = np.unique(ypredict_two))\n",
    "\n",
    "\n",
    "fpr_two, tpr_two, threshold_two = roc_curve(ytest_two, ypredict_two)\n",
    "roc_auc_two = auc(fpr_two, tpr_two)\n",
    "\n",
    "score_summary = {'Accuracy':round(accuracy_two,2), 'Precision':round(precision_two,2), 'Recall': round(recall_two,2), 'F1': round(f1_two,2)}\n",
    "\n",
    "for key, value in score_summary.items():\n",
    "    print(f'{key} Score is: {value}')\n",
    "print(matrix_two)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e8c489-968d-4ce5-9d3e-2232a883bb9a",
   "metadata": {},
   "source": [
    "<b> Test 3 </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b253db8-32a7-40eb-8e38-8e9c1e719164",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_number_three = differentiate_columns + sixth_stage_columns + t_stage_columns + ['age'] + ['survival_chance']\n",
    "\n",
    "feature_set_three = test_number_three\n",
    "target_set_three = ['status']\n",
    "feature_three = df_verFive.loc[:,feature_set_three]\n",
    "target_three = df_verFive.loc[:,target_set_three]\n",
    "\n",
    "Xtrain_three, Xtest_three, ytrain_three, ytest_three = train_test_split(\n",
    "    feature_three,\n",
    "    target_three,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_three = GaussianNB()\n",
    "model_three.fit(Xtrain_three, ytrain_three)\n",
    "ypredict_three = model_three.predict(Xtest_three)\n",
    "\n",
    "accuracy_three = accuracy_score(ytest_three, ypredict_three)\n",
    "matrix_three = confusion_matrix(ytest_three, ypredict_three)\n",
    "precision_three = precision_score(ytest_three, ypredict_three, average='weighted', labels = np.unique(ypredict_three))\n",
    "recall_three = recall_score(ytest_three, ypredict_three, average='weighted', labels = np.unique(ypredict_three))\n",
    "f1_three = f1_score(ytest_three, ypredict_three, average='weighted', labels = np.unique(ypredict_three))\n",
    "\n",
    "fpr_three, tpr_three, threshold_three = roc_curve(ytest_three, ypredict_three)\n",
    "roc_auc_three = auc(fpr_three, tpr_three)\n",
    "\n",
    "score_summary = {'Accuracy':round(accuracy_three,2), 'Precision':round(precision_three,2), 'Recall': round(recall_three,2), 'F1': round(f1_three,2)}\n",
    "\n",
    "for key, value in score_summary.items():\n",
    "    print(f'{key} Score is: {value}')\n",
    "print(matrix_three)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d859f6f-e8aa-43ec-8b6c-46090f9c84f7",
   "metadata": {},
   "source": [
    "<b> Test 4 </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066702ad-9adf-43c9-beac-cb61986f9f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_number_four = sixth_stage_columns + t_stage_columns + differentiate_columns + ['survival_chance']\n",
    "\n",
    "feature_set_four = test_number_four\n",
    "target_set_four = ['status']\n",
    "feature_four = df_verFive.loc[:,feature_set_four]\n",
    "target_four = df_verFive.loc[:,target_set_four]\n",
    "\n",
    "Xtrain_four, Xtest_four, ytrain_four, ytest_four = train_test_split(\n",
    "    feature_four,\n",
    "    target_four,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_four = SVC(kernel='linear')\n",
    "model_four.fit(Xtrain_four, ytrain_four)\n",
    "ypredict_four = model_four.predict(Xtest_four)\n",
    "\n",
    "accuracy_four = accuracy_score(ytest_four, ypredict_four)\n",
    "matrix_four = confusion_matrix(ytest_four, ypredict_four)\n",
    "precision_four = precision_score(ytest_four, ypredict_four, average='weighted', labels = np.unique(ypredict_four))\n",
    "recall_four = recall_score(ytest_four, ypredict_four, average='weighted', labels = np.unique(ypredict_four))\n",
    "f1_four = f1_score(ytest_four, ypredict_four, average='weighted', labels = np.unique(ypredict_four))\n",
    "\n",
    "\n",
    "fpr_four, tpr_four, threshold_four = roc_curve(ytest_four, ypredict_four)\n",
    "roc_auc_four = auc(fpr_four, tpr_four)\n",
    "\n",
    "\n",
    "score_summary = {'Accuracy':round(accuracy_three,2), 'Precision':round(precision_three,2), 'Recall': round(recall_three,2), 'F1': round(f1_three,2)}\n",
    "\n",
    "for key, value in score_summary.items():\n",
    "    print(f'{key} Score is: {value}')\n",
    "print(matrix_four)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad55f20d-5cff-471a-821a-a2a74eeece74",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27db06a0-5e36-49fa-a7a3-535e102527e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize = (10,6))\n",
    "\n",
    "sb.heatmap(matrix_one, cmap = 'Blues_r', annot=True, fmt ='d', ax= ax[0,0])\n",
    "ax[0,0].set_xlabel('Predicted Death Event')\n",
    "ax[0,0].set_ylabel('Actual Death Event')\n",
    "ax[0,0].set_title('Estimating Death Event using Random Forest Classifier')\n",
    "\n",
    "sb.heatmap(matrix_two, cmap = 'Blues_r', annot=True, fmt ='d', ax= ax[0,1])\n",
    "ax[0,1].set_xlabel('Predicted Death Event')\n",
    "ax[0,1].set_ylabel('Actual Death Event')\n",
    "ax[0,1].set_title('Estimating Death Event using Logistic Regression')\n",
    "\n",
    "sb.heatmap(matrix_three, cmap = 'Blues_r', annot=True, fmt ='d', ax= ax[1,0])\n",
    "ax[1,0].set_xlabel('Predicted Death Event')\n",
    "ax[1,0].set_ylabel('Actual Death Event')\n",
    "ax[1,0].set_title('Estimating Death Event using Gaussian Naive Bayes')\n",
    "\n",
    "sb.heatmap(matrix_four, cmap = 'Blues_r', annot=True, fmt ='d', ax= ax[1,1])\n",
    "ax[1,1].set_xlabel('Predicted Death Event')\n",
    "ax[1,1].set_ylabel('Actual Death Event')\n",
    "ax[1,1].set_title('Estimating Death Event using SVC')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53a2253-8304-41d4-b032-34dcd9fd94a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(fpr_one, tpr_one, label = 'AUC = %0.2f' % roc_auc_one)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) of Random Forest Classifier')\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(fpr_two, tpr_two, label = 'AUC = %0.2f' % roc_auc_two)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) of Logistic Regression')\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(fpr_three, tpr_three, label = 'AUC = %0.2f' % roc_auc_three)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) of Gaussian Naive Bayes')\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(fpr_four, tpr_four, label = 'AUC = %0.2f' % roc_auc_four)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) of SVC')\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04813da8-4f1e-43a4-ade9-0f11115165fe",
   "metadata": {},
   "source": [
    "<h2> Summary of Our Findings (Classification)</h2>\n",
    "<div>\n",
    "    <p>We ran Four tests, using different models and features each time around: </p>\n",
    "    <p>For Test 1, we used Random Forest Classifier Model and all differentiate, relationship columns plus age. </p>\n",
    "    <p>For Test 2, we used the Logistic Regression Model and Only the relationship column. This resulted in the model with the perfect recall score</p>\n",
    "    <p>For Test 3, we used Gaussian Naive Bayes and included all the columns except The target.</p>\n",
    "    <p> For Test 4, we included differentiate, tstage, and sixth stage columns plus the surival chance column the we feature engineered. The model used was SVC.</p>\n",
    "\n",
    "    <p>The results of our comparision are summarized below: </p>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff25040-6fe6-41dc-91c3-70ce30d533b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['Accuracy','Precision','Recall','F1_Score']\n",
    "values1 = [accuracy_one,precision_one,recall_one,f1_one]\n",
    "values2 = [accuracy_two,precision_two,recall_two,f1_two]\n",
    "values3 = [accuracy_three,precision_three,recall_three,f1_three]\n",
    "values4 = [accuracy_four,precision_four,recall_four,f1_four]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.bar(np.arange(len(metrics)) - 0.4, values1, width=0.2, label='Metrics Set 1')\n",
    "plt.bar(np.arange(len(metrics)) - 0.2, values2, width=0.2, label='Metrics Set 2')\n",
    "plt.bar(np.arange(len(metrics)) + 0, values3, width=0.2, label='Metrics Set 3')\n",
    "plt.bar(np.arange(len(metrics)) + 0.2, values4, width=0.2, label='Metrics Set 4')\n",
    "\n",
    "plt.xticks(np.arange(len(metrics)), metrics) \n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of Evaluation Metrics')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f51fd24-a163-467a-8b76-570452c17489",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3>\n",
    "<p>From the AUC curves and our comparison matrix, we can conclude that Gaussian Naive Bayes Model performed the best\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da21970-597b-48f9-a32d-f814b8bea65e",
   "metadata": {},
   "source": [
    "<div>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c33241-f9f8-4147-8647-d0dbce3c1aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6840e00a-7faf-472f-9dd5-c5aa02d533a9",
   "metadata": {},
   "source": [
    "<p><b>Regression Problem:</b> Number of survival months remaining for patients</p>\n",
    "\n",
    "<b>Test One</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b360fba4-fe7b-4e08-8cb4-5fdcb6dcabb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verSix = df_verFive.copy()\n",
    "df_verSix['survival_months'] = denormalize(original=df_verOne['survival_months'], normalized= df_verFive['survival_months'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7449f2f-3eaf-4434-959f-5510d0d77474",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_test_number_one = relationship_status_columns + ['age', 'survival_chance'] + t_stage_columns\n",
    "\n",
    "reg_feature_set_one = reg_test_number_one\n",
    "reg_target_set_one = ['survival_months']\n",
    "reg_feature_one = df_verSix.loc[:,reg_feature_set_one]\n",
    "reg_target_one = df_verSix.loc[:,reg_target_set_one]\n",
    "\n",
    "reg_Xtrain_one, reg_Xtest_one, reg_ytrain_one, reg_ytest_one = train_test_split(\n",
    "    reg_feature_one,\n",
    "    reg_target_one,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "reg_model_one = GradientBoostingRegressor()\n",
    "reg_model_one.fit(reg_Xtrain_one, reg_ytrain_one)\n",
    "reg_ypredict_one = reg_model_one.predict(reg_Xtest_one)\n",
    "\n",
    "r2_score_one = r2_score(reg_ytest_one, reg_ypredict_one)\n",
    "mse_one = mean_squared_error(reg_ytest_one, reg_ypredict_one)\n",
    "rmse_one = np.sqrt(mse_one)\n",
    "\n",
    "\n",
    "score_summary = {'R2 Score':round(r2_score_one,2), 'Mean Squared Error:':round(mse_one,2), 'Root Mean Squared Error:': round(rmse_one,2)}\n",
    "\n",
    "for key, value in score_summary.items():\n",
    "    print(f'{key} Score is: {value}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bcf80f-5a85-44d5-9777-770384b1ef4b",
   "metadata": {},
   "source": [
    "<b> Test Two </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b481861-ae29-482a-9ef8-9609c6b62fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62573090-c35e-4ff7-a8d9-4a8f23c1e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_test_number_two = [column for column in df_verSix.columns if not column == 'survival_months']\n",
    "\n",
    "reg_feature_set_two = reg_test_number_two\n",
    "reg_target_set_two = [column for column in df_verSix.columns if column == 'survival_months']\n",
    "reg_feature_two = df_verSix.loc[:,reg_feature_set_two]\n",
    "reg_target_two = df_verSix.loc[:,reg_target_set_two]\n",
    "\n",
    "reg_Xtrain_two, reg_Xtest_two, reg_ytrain_two, reg_ytest_two = train_test_split(\n",
    "    reg_feature_two,\n",
    "    reg_target_two,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "reg_model_two = PoissonRegressor()\n",
    "reg_model_two.fit(reg_Xtrain_two, reg_ytrain_two)\n",
    "reg_ypredict_two = reg_model_two.predict(reg_Xtest_two)\n",
    "\n",
    "r2_score_two = r2_score(reg_ytest_two, reg_ypredict_two)\n",
    "mse_two = mean_squared_error(reg_ytest_two, reg_ypredict_two)\n",
    "rmse_two = np.sqrt(mse_two)\n",
    "\n",
    "\n",
    "score_summary = {'R2 Score':round(r2_score_two,2), 'Mean Squared Error:':round(mse_two,2), 'Root Mean Squared Error:': round(rmse_two,2)}\n",
    "\n",
    "for key, value in score_summary.items():\n",
    "    print(f'{key} Score is: {value}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03ec2bd-613d-4bd5-8f7c-0a249d840a7a",
   "metadata": {},
   "source": [
    "<b> Test Three </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff204b4-7717-4975-847c-c067ac1fcfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_test_number_three = [column for column in df_verSix.columns if not column == 'survival_months']\n",
    "\n",
    "reg_feature_set_three = reg_test_number_three\n",
    "reg_target_set_three = [column for column in df_verSix.columns if column == 'survival_months']\n",
    "reg_feature_three = df_verSix.loc[:,reg_feature_set_three]\n",
    "reg_target_three = df_verSix.loc[:,reg_target_set_three]\n",
    "\n",
    "reg_Xtrain_three, reg_Xtest_three, reg_ytrain_three, reg_ytest_three = train_test_split(\n",
    "    reg_feature_three,\n",
    "    reg_target_three,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "reg_model_three = RandomForestQuantileRegressor()\n",
    "reg_model_three.fit(reg_Xtrain_three, reg_ytrain_three)\n",
    "reg_ypredict_three = reg_model_three.predict(reg_Xtest_three)\n",
    "\n",
    "r2_score_three = r2_score(reg_ytest_two, reg_ypredict_three)\n",
    "mse_three = mean_squared_error(reg_ytest_three, reg_ypredict_three)\n",
    "rmse_three = np.sqrt(mse_three)\n",
    "\n",
    "score_summary = {'R2 Score':round(r2_score_three,2), 'Mean Squared Error:':round(mse_three,2), 'Root Mean Squared Error:': round(rmse_three,2)}\n",
    "\n",
    "for key, value in score_summary.items():\n",
    "    print(f'{key} Score is: {value}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e292580-fc50-4a69-a0f8-2d4bdba0a87c",
   "metadata": {},
   "source": [
    "<b>Plotting a Clustered Bar Chart In Order to Compare the different Models</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01842141-b2b3-4da7-883f-38d19f176847",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score = [r2_score_one,r2_score_two, r2_score_three]\n",
    "mse_score = [mse_one,mse_two, mse_three]\n",
    "rmse_score = [rmse_one, rmse_two, rmse_three]\n",
    "\n",
    "norm_r2_score_one = logtrans(pd.Series(r2_score), inverse=True).tolist()[0]\n",
    "norm_r2_score_two = logtrans(pd.Series(r2_score), inverse=True).tolist()[1]\n",
    "norm_r2_score_three = logtrans(pd.Series(r2_score), inverse=True).tolist()[2]\n",
    "\n",
    "norm_mse_score_one = logtrans(pd.Series(mse_score)).tolist()[0]\n",
    "norm_mse_score_two = logtrans(pd.Series(mse_score)).tolist()[1]\n",
    "norm_mse_score_three = logtrans(pd.Series(mse_score)).tolist()[2]\n",
    "\n",
    "norm_rmse_score_one = logtrans(pd.Series(rmse_score)).tolist()[0]\n",
    "norm_rmse_score_two = logtrans(pd.Series(rmse_score)).tolist()[1]\n",
    "norm_rmse_score_three = logtrans(pd.Series(rmse_score)).tolist()[2]\n",
    "\n",
    "\n",
    "# Normalizing RMSE and MSE score to bring on the same scale as R2 score. Otherwise their values are really imbalancedly scaled\n",
    "\n",
    "metrics = ['R2 Score', 'Mean Squared Error','Root Mean Squared Error']\n",
    "\n",
    "\n",
    "values1 = [norm_r2_score_one, norm_mse_score_one, norm_rmse_score_one]\n",
    "values2 = [norm_r2_score_two, norm_mse_score_two, norm_rmse_score_two]\n",
    "values3 = [norm_r2_score_three, norm_mse_score_three, norm_rmse_score_three]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.bar(np.arange(len(metrics)) - 0.2, values1, width=0.2, label='Metrics Set 1')\n",
    "plt.bar(np.arange(len(metrics)), values2, width=0.2, label='Metrics Set 2')\n",
    "plt.bar(np.arange(len(metrics)) + 0.2, values3, width=0.2, label='Metrics Set 3')\n",
    "\n",
    "plt.xticks(np.arange(len(metrics)), metrics)\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of Evaluation Metrics')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfcc844-5eb7-40b0-bbed-98f813e05e34",
   "metadata": {},
   "source": [
    "<b> Important Note: </b> Higher the MSE and RMSE, the worse the model is performing. The inverse is true for R2 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f2f2a7-1109-4661-8151-eae7b44c3b81",
   "metadata": {},
   "source": [
    "<h3>Summary of Our Findings (Regression)</h3>\n",
    "\n",
    "<div>\n",
    "    <p>We ran three tests, using different models and features each time around: </p>\n",
    "    <p>For Test 1, we used Gradient Boosting Regressor model and relationship, age, survival_change, and t_stage columns </p>\n",
    "    <p>For Test 2, we used the Poisson Regressor Model and All Columns.</p>\n",
    "    <p>For Test 3, we used Random Forest Quantile Regressor and included all the columns again</p>\n",
    "    <p>The results of our comparision are summarized in the figure above:</p>\n",
    "    <p>The third model resulted in the best overall R2 Score, lower MSE score, and the lowest RMSE Score, which makes it the best model for predicting survival month of the patients</p>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1451531-7b0e-45b5-bfa5-0301e94ca79f",
   "metadata": {},
   "source": [
    "<h3>How can Accuracy of Classification Model and Regression Model Be Improved?</h3>\n",
    "<p> The models could be improved by including a column that measures the critical status of the patient given their past visits and family history.\n",
    "Family history is a big one. it would be really helpful to know if the patient has had previous family members who were in risk of having breast cancer or have had breast cancer.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88a1a39-fecd-4d0f-8ff2-fdf8ef3ad06c",
   "metadata": {},
   "source": [
    "<h1> References</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23febee4-c762-413f-8459-acd72a3fe505",
   "metadata": {},
   "source": [
    "<p>Breast cancer tumor size chart & measurement explained. (n.d.). City of Hope. <a href = 'https://www.cancercenter.com/cancer-types/breast-cancer/stages/tumor-size-chart'>https://www.cancercenter.com/cancer-types/breast-cancer/stages/tumor-size-chart</a> </p>\n",
    "\n",
    "<p>Regular Expressions: Search in list. (n.d.). Stack Overflow. <a href = \">https://stackoverflow.com/questions/3640359/regular-expressions-search-in-list\">https://stackoverflow.com/questions/3640359/regular-expressions-search-in-list </a></p>\n",
    "<p>Rosen, T. (2021b, December 10). Choosing the right estimator - Tara Rosen - medium. <a href = \"https://medium.com/@t.rosen2101/choosing-the-right-estimator-ae054809b693\">Medium. https://medium.com/@t.rosen2101/choosing-the-right-estimator-ae054809b693</a></p>\n",
    "<p> TracyRenee. (n.d.). Misc-Predictions/Denormalise_Destandardise_data.ipynb at main · TracyRenee61/Misc-Predictions. GitHub. <a href = \"https://github.com/TracyRenee61/Misc-Predictions/blob/main/Denormalise_Destandardise_data.ipynb\">https://github.com/TracyRenee61/Misc-Predictions/blob/main/Denormalise_Destandardise_data.ipynb</a></p>\n",
    "<p> GfG. (2022, September 30). How to rotate X-Axis Tick label text in Matplotlib? GeeksforGeeks. <a href = 'https://www.geeksforgeeks.org/how-to-rotate-x-axis-tick-label-text-in-matplotlib/'>https://www.geeksforgeeks.org/how-to-rotate-x-axis-tick-label-text-in-matplotlib/</a></p>\n",
    "<p>Numeracy, Maths and Statistics - Academic Skills kit. (n.d.). <a href = 'https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/data-presentation/box-and-whisker-plots.html#:~:text=Definition,than%20one%20boxplot%20per%20graph.'>https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/data-presentation/box-and-whisker-plots.html#:~:text=Definition,than%20one%20boxplot%20per%20graph.</a></p>\n",
    "<p> <a href = ''></a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96cf6a8-a644-4d84-b60c-6b461de0e87a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c18b78-6497-45ba-8a1c-b25202bf4df6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
